\documentclass[fleqn,10pt]{wlscirep}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{todonotes}

\title{A preprocessed open diffusion derivatives dataset from the Healthy Brain Network}

\author[1,*$\dagger$]{Adam Richie-Halford}
\author[2,$\dagger$]{Matthew Cieslak}
\author[4]{Lei Ai}
\author[5]{Sendy Caffarra}
\author[4]{Alexandre R. Franco}
\author[5]{Iliana Karipidis}
\author[3]{John Kruper}
\author[5]{Barbara Avelar Pereira}
\author[5]{Ethan Roy}
\author[2]{Valerie J. Sydnor}
\author[5]{Jason Yeatman}
\author[4]{Michael Milham}
\input{fibr_authors.tex}
\author[2,+]{Theodore D. Satterthwaite}
\author[3,1,+]{Ariel Rokem}

\affil[1]{University of Washington, eScience Institute, Seattle, Washington, 98195, USA}
\affil[2]{University of Pennsylvania, Department of Psychiatry, Philadelphia, Pennsylvania, 19104, USA}
\affil[3]{University of Washington, Department of Psychology, Seattle, Washington, 98195, USA}
\affil[4]{Child Mind Institute, New York City, 10022, USA}
\affil[5]{Stanford University, Graduate School of Education and Division of Developmental and Behavioral Pediatrics, Stanford, California, 94305, USA}
\affil[6]{The Fibr Community Science Consortium}

\affil[*]{richford@uw.edu}
\affil[$\dagger$]{these authors contributed equally to this work}
\affil[+]{these authors contributed equally to this work}

%\keywords{Keyword1, Keyword2, Keyword3}

\begin{abstract}
\todo[inline]{Write abstract}
\end{abstract}
\begin{document}

\flushbottom
\maketitle
\thispagestyle{empty}

\section*{Introduction}

The Healthy Brain Network (HBN) is a landmark pediatric mental health study collecting MRI images and clinical assessment data from 10,000 New York City area children and adolescents \cite{alexander2017-yc}. The HBN dataset contains a wealth of phenotypic and imaging data, including diffusion MRI (dMRI) data, which allows for analysis of the physical properties of developing white matter (Wandell 2016). This dMRI data is openly available in raw form through the Functional Connectomes Project and the International Neuroimaging Data-Sharing Initiative (FCP-INDI), spurring collaboration on open big-data reproducible science (Avesani 2019). However, analysis of dMRI data must start with a pipeline of critical preprocessing steps, such as eddy current correction, motion correction, and adjustment of the gradient directions. Because of the complexity of some of these steps, investigators may neglect to perform preprocessing or may make errors that can induce bias in their subsequent interpretation of the data (Jones 2010). Furthermore, once preprocessing is done correctly and transparently once, there is little need for researchers to repeat this step. Thus, there is a need for an openly available preprocessed diffusion derivative dataset that applies best practices in preprocessing in a robust and transparent way (Cieslak 2020). Accordingly, here we introduce the HBN Preprocessed Open Diffusion Derivatives (HBN-POD2), a large dataset for the analysis of structural brain connectivity and pediatric mental health.

\section*{Results}

Outputs from each of the curation and preprocessing steps, as well as QC ratings, are openly available on FCP-INDI. Similarly, HBN-POD2 offers open QC metrics, eliminating the need for investigators to repeat quality assessment for over 2,000 scans. Using a previously developed cloud-computing library 7 to parallelize the preprocessing over individual subjects on spot instances in the Amazon Web Services Batch service, this dMRI preprocessing cost less than \textdollar1.00 per subject.

\section*{Discussion}

We present HBN-POD2, one of the largest youth diffusion imaging datasets with derived measures currently available. It is openly available and complies with the current draft of the BIDS diffusion derivative specification. It will grow continuously as the HBN study acquires more data, eventually reaching its 10,000 subject goal. The data is amenable to many different analyses, including tractometry (Yeatman 2012), graph theoretical analysis (Yeh 2020), and combinations with functional data for the same subjects. The availability of standardized preprocessed diffusion data will allow researchers to create and test hypotheses on the white matter properties underlying behavior and disease, from reading and math acquisition to childhood adversity and mental health. As such, this dataset will accelerate discovery at the nexus of structural connectivity and neurodevelopmental and learning disorders.

\section*{Methods}


Diffusion MRI data from the Healthy Brain Network pediatric mental health study \cite{alexander2017-yc}, containing dMRI data from 1651 subjects with ages 5-21. These data were measured in 3T Siemens MRI scanners at four sites in the New York area: Rutgers University Brain Imaging Center (RU), the CitiGroup Cornell Brain Imaging Center (CBIC), CUNY, and SI. \todo[inline]{Add full names for CUNY and SI.} Informed consent was obtained from each participant aged 18 or older. For participants younger than 18, written consent was obtained from their legal guardians and written assent was obtained from the participant. Voxel resolution was $1.8 \times 1.8 \times 1.8 \text{mm}^3$ with 64 non-colinear directions measured for each of $b=1000 \text{s} / \text{mm}^2$ and $b=2000 \text{s} / \text{mm}^2$.

\subsection*{BIDS curation}

We curated the imaging metadata for 2,615 of the 2,747 currently available HBN subjects. Using dcm2bids and custom scripts, we conformed the data to the Brain Imaging Data Structure (BIDS; \cite{gorgolewski2016-lh}) specification.

\todo[inline]{Add more BIDS curation information}

\subsection*{Preprocessing}

We performed dMRI preprocessing on 2,136 subjects, using \emph{QSIPrep}
\cite{cieslak2021-iq} 0.12.1, which is based on \emph{Nipype} 1.5.1
\cite{nipype1,nipype2}, RRID:SCR\_002502. \emph{QSIPrep} a robust and scalable
pipeline to group, distortion correct, motion correct, denoise, coregister and
resample MRI scans.  In total, 417 subjects failed this preprocessing step,
largely due to missing dMRI files.

\emph{QSIPrep} fosters reproducibility by automatically generating thorough
methods boilerplate for later use in scientific publications, which we use for
the remainder of this subsection to document each preprocessing step.

\begin{itemize}

\item {\it Anatomical data preprocessing}
The T1-weighted (T1w) image was corrected for intensity non-uniformity
(INU) using \texttt{N4BiasFieldCorrection} \cite[ANTs 2.3.1]{n4}, and
used as T1w-reference throughout the workflow. The T1w-reference was
then skull-stripped using \texttt{antsBrainExtraction.sh} (ANTs 2.3.1),
using OASIS as target template. Spatial normalization to the ICBM 152
Nonlinear Asymmetrical template version 2009c
\cite{mni}, RRID:SCR\_008796 was performed through nonlinear
registration with \texttt{antsRegistration} \cite{ants}, ANTs 2.3.1,
RRID:SCR\_004757, using brain-extracted versions of both T1w
volume and template. Brain tissue segmentation of cerebrospinal fluid
(CSF), white-matter (WM) and gray-matter (GM) was performed on the
brain-extracted T1w using \texttt{FAST} \cite{fsl_fast}, FSL 6.0.3:b862cdd5, RRID:SCR\_002823.

\item {\it Diffusion data preprocessing}

Any images with a b-value less than 100 s/mm\^{}2 were treated as a
\emph{b}=0 image. MP-PCA denoising as implemented in MRtrix3's
\texttt{dwidenoise}\cite{dwidenoise1} was applied with a 5-voxel
window. After MP-PCA, B1 field inhomogeneity was corrected using
\texttt{dwibiascorrect} from MRtrix3 with the N4 algorithm \cite{n4}.
After B1 bias correction, the mean intensity of the DWI series was
adjusted so all the mean intensity of the b=0 images matched across
eachseparate DWI scanning sequence.

FSL (version 6.0.3:b862cdd5)'s eddy was used for head motion correction
and Eddy current correction \cite{anderssoneddy}. Eddy was configured
with a \(q\)-space smoothing factor of 10, a total of 5 iterations, and
1000 voxels used to estimate hyperparameters. A linear first level model
and a linear second level model were used to characterize Eddy
current-related spatial distortion. \(q\)-space coordinates were
forcefully assigned to shells. Field offset was attempted to be
separated from subject movement. Shells were aligned post-eddy. Eddy's
outlier replacement was run \cite{eddyrepol}. Data were grouped by
slice, only including values from slices determined to contain at least
250 intracerebral voxels. Groups deviating by more than 4 standard
deviations from the prediction had their data replaced with imputed
values. Data was collected with reversed phase-encode blips, resulting
in pairs of images with distortions going in opposite directions. Here,
b=0 reference images with reversed phase encoding directions were used
along with an equal number of b=0 images extracted from the DWI scans.
From these pairs the susceptibility-induced off-resonance field was
estimated using a method similar to that described in \cite{topup}. The
fieldmaps were ultimately incorporated into the Eddy current and head
motion correction interpolation. Final interpolation was performed using
the \texttt{jac} method.

Several confounding time-series were calculated based on the
\emph{preprocessed DWI}: framewise displacement (FD) using the implementation
in \emph{Nipype} following the definitions by \cite{power_fd_dvars}. The DWI
time-series were resampled to ACPC, generating a \emph{preprocessed DWI run
in ACPC space}.

\item {\it MRtrix3 Reconstruction}

Reconstruction was performed using \emph{QSIprep} 0.12.1. Multi-tissue fiber response functions were estimated using the dhollander algorithm. FODs were estimated via constrained spherical deconvolution (CSD, \cite{originalcsd, tournier2008csd}) using an unsupervised multi-tissue method \cite{dhollander2019response, dhollander2016unsupervised}. Reconstruction was done using MRtrix3 \cite{mrtrix3}. FODs were intensity-normalized using mtnormalize \cite{mtnormalize}.

\end{itemize}

Many internal operations of \emph{QSIPrep} use \emph{Nilearn} 0.6.2 \cite{nilearn}, RRID:SCR\_001362 and \emph{DIPY} \cite{dipy}. For more details of the pipeline, see \href{https://qsiprep.readthedocs.io/en/latest/workflows.html}{the section corresponding to workflows in \emph{QSIPrep}'s documentation}.

\subsection*{Cloud-based distributed preprocessing}

\todo[inline]{Add information on cloudknot}

\subsection*{Expert quality control}

\todo[inline]{Add information on dmriprep-viewer, the QC instruction video, and the expert QC}

\subsection*{Community scientist quality control}

To assess image quality, we released a citizen science web application, drawing on the success of a previous application in assessing the quality of HBN's structural MRI data \cite{keshavan2019-er}. After a brief tutorial, citizen scientists provided binary pass/fail ratings based on the directionally-colorized fractional anisotropy from DTI of each subject's preprocessed dMRI data. These citizen scientist ratings were then combined with expert ratings to train a neural network to assign a quality control (QC) rating to each subject.

\subsection*{Deep learning to predict quality control}

\subsection*{Brain age prediction}

\bibliography{hbn-pod2}

\section*{Acknowledgements}

We would like to thank Anisha Keshavan for useful discussions of community science and web-based quality control. This manuscript was prepared using a limited access dataset obtained from the Child Mind Institute Biobank, The Healthy Brain Network dataset. This manuscript reflects the views of the authors and does not necessarily reflect the opinions or views of the Child Mind Institute.

\todo[inline]{Add grant numbers.}

\section*{Author contributions statement}

The first author named is the corresponding author.
The last two authors named share senior authorship.
The first two authors named share lead authorship.
The next ten authors' contributions extended beyond providing community science annotations and are listed in alphabetical order.
All other authors are Fibr community scientists and are listed in descending order of the number of QC labels they produced.

\todo[inline]{Please add your initials here as appropriate}

We describe contributions to the paper using the CRediT taxonomy \cite{brand2015-vd}:
\begin{itemize}
    \item Conceptualization: A.R-H., A.R., T.S., and M.C.;
    \item Methodology: A.R-H. and A.R.;
    \item Software: A.R-H. and M.C.;
    \item Validation: ;
    \item Formal Analysis: A.R-H. and M.C.;
    \item Investigation: A.R-H. and M.C.;
    \item Resources: M.M.;
    \item Data curation: M.C. and L.A.;
    \item Writing – Original Draft: A.R-H. and A.R.;
    \item Writing – Review \& Editing: ;
    \item Visualization: A.R-H.;
    \item Supervision: A.R. and T.S.;
    \item Project Administration: A.R-H. and A.R.;
    \item Funding Acquisition: A.R. and T.S.
\end{itemize}

\section*{Additional information}

To include, in this order: \textbf{Accession codes} (where applicable); \textbf{Competing interests} (mandatory statement). 

The corresponding author is responsible for submitting a \href{http://www.nature.com/srep/policies/index.html#competing}{competing interests statement} on behalf of all authors of the paper. This statement must be included in the submitted article file.

% \begin{figure}[ht]
% \centering
% \includegraphics[width=\linewidth]{stream}
% \caption{Legend (350 words max). Example legend text.}
% \label{fig:stream}
% \end{figure}

% \begin{table}[ht]
% \centering
% \begin{tabular}{|l|l|l|}
% \hline
% Condition & n & p \\
% \hline
% A & 5 & 0.1 \\
% \hline
% B & 10 & 0.01 \\
% \hline
% \end{tabular}
% \caption{\label{tab:example}Legend (350 words max). Example legend text.}
% \end{table}

% Figures and tables can be referenced in LaTeX using the ref command, e.g. Figure \ref{fig:stream} and Table \ref{tab:example}.

\end{document}